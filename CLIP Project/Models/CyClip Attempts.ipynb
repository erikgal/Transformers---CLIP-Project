{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPeQ1ZqY8pAoXn1gsFZgNOp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["First CyClip Attempt, very poor results"],"metadata":{"id":"XwCXJBUrndyF"}},{"cell_type":"code","source":["def forward(self, batch):\n","    # Getting Image and Text Features\n","    image_features = self.image_encoder(batch[\"image\"])\n","    text_features = self.text_encoder(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n","\n","    # Getting Image and Text Embeddings (with same dimension)\n","    image_embeddings = self.image_projection(image_features)\n","    text_embeddings = self.text_projection(text_features)\n","    criterion = nn.CrossEntropyLoss(reduction = \"sum\").to(CFG.device)\n","\n","    # Calculating the Loss\n","    logits = (text_embeddings @ image_embeddings.T) / self.temperature\n","    targets = torch.arange(batch['input_ids'].shape[0]).to(CFG.device)\n","    contrastive_loss = (criterion(logits, targets) + criterion(logits.T, targets.T)) / 2\n","\n","    # In-modal consistency\n","    logits_image_per_image = image_embeddings @ image_embeddings.T / self.temperature\n","    logits_text_per_text = text_embeddings @ text_embeddings.T / self.temperature\n","    inmodal_cyclic_loss = (logits_image_per_image - logits_text_per_text).square().mean() * (self.temperature * self.temperature) * CFG.batch_size\n","\n","    # Cross-modal consistency\n","    logits_text_per_image = image_embeddings @ text_embeddings.T / self.temperature\n","    logits_image_per_text = logits_text_per_image.T\n","    crossmodal_cyclic_loss = (logits_text_per_image - logits_image_per_text).square().mean() * (self.temperature * self.temperature) * CFG.batch_size\n","\n","    cyclic_loss = CFG.cylambda1 * inmodal_cyclic_loss + CFG.cylambda2 * crossmodal_cyclic_loss\n","    loss = contrastive_loss + cyclic_loss\n","\n","    correct_preds = num_of_correct_preds(logits, batch['caption'])\n","\n","    return loss, correct_preds"],"metadata":{"id":"Q8S_YndOndYO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["No CyClip, but reformatted the loss function to with same code as in the paper. Gave equal results as previous 100_pre_trained model!"],"metadata":{"id":"GGLrIAAwKRDP"}},{"cell_type":"code","source":["    def forward(self, batch):\n","        # Getting Image and Text Features\n","        image_features = self.image_encoder(batch[\"image\"])\n","        text_features = self.text_encoder(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n","        batch_size = batch['input_ids'].shape[0]\n","\n","        # Getting Image and Text Embeddings (with same dimension)\n","        image_embeddings = self.image_projection(image_features)\n","        text_embeddings = self.text_projection(text_features)\n","        criterion = nn.CrossEntropyLoss(reduction = \"sum\").to(CFG.device)\n","\n","        # Cross-modal contrastive alignment (CLIP)\n","        logits_text_per_image = image_embeddings @ text_embeddings.T / self.temperature\n","        logits_image_per_text = logits_text_per_image.T\n","        target = torch.arange(batch_size).long().to(CFG.device, non_blocking = True)\n","        contrastive_loss = (criterion(logits_text_per_image, target) + criterion(logits_image_per_text, target)) / 2\n","\n","        # In-modal consistency (CyCLIP)\n","        logits_image_per_image = image_embeddings @ image_embeddings.T / self.temperature\n","        logits_text_per_text = text_embeddings @ text_embeddings.T / self.temperature\n","        inmodal_cyclic_loss = (logits_image_per_image - logits_text_per_text).square().mean() * (self.temperature * self.temperature) * batch_size\n","\n","        # Cross-modal consistency (CyCLIP)\n","        crossmodal_cyclic_loss = (logits_text_per_image - logits_image_per_text).square().mean() * (self.temperature * self.temperature) * batch_size\n","\n","        cyclic_loss = CFG.cylambda1 * inmodal_cyclic_loss + CFG.cylambda2 * crossmodal_cyclic_loss\n","        loss = contrastive_loss #+ cyclic_loss\n","\n","        correct_preds = num_of_correct_preds(logits_image_per_text, batch['caption'])\n","\n","        return loss, correct_preds"],"metadata":{"id":"dLQTvFZ0KR7Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Same as above, but with CyCLIP loss. hadde pretty poor result ending on 0.1559"],"metadata":{"id":"J_L6cg60whmi"}},{"cell_type":"code","source":["def forward(self, batch):\n","    # Getting Image and Text Features\n","    image_features = self.image_encoder(batch[\"image\"])\n","    text_features = self.text_encoder(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n","\n","    # Getting Image and Text Embeddings (with same dimension)\n","    image_embeddings = self.image_projection(image_features)\n","    text_embeddings = self.text_projection(text_features)\n","    criterion = nn.CrossEntropyLoss(reduction = \"sum\").to(CFG.device)\n","\n","    # Calculating the Loss\n","    logits = (text_embeddings @ image_embeddings.T) / self.temperature\n","    targets = torch.arange(batch['input_ids'].shape[0]).to(CFG.device)\n","    contrastive_loss = (criterion(logits, targets) + criterion(logits.T, targets.T)) / 2\n","\n","    # In-modal consistency\n","    logits_image_per_image = image_embeddings @ image_embeddings.T / self.temperature\n","    logits_text_per_text = text_embeddings @ text_embeddings.T / self.temperature\n","    inmodal_cyclic_loss = (logits_image_per_image - logits_text_per_text).square().mean() * (self.temperature * self.temperature) * CFG.batch_size\n","\n","    # Cross-modal consistency\n","    logits_text_per_image = image_embeddings @ text_embeddings.T / self.temperature\n","    logits_image_per_text = logits_text_per_image.T\n","    crossmodal_cyclic_loss = (logits_text_per_image - logits_image_per_text).square().mean() * (self.temperature * self.temperature) * CFG.batch_size\n","\n","    cyclic_loss = CFG.cylambda1 * inmodal_cyclic_loss + CFG.cylambda2 * crossmodal_cyclic_loss\n","    loss = contrastive_loss + cyclic_loss\n","\n","    correct_preds = num_of_correct_preds(logits, batch['caption'])\n","\n","    return loss, correct_preds"],"metadata":{"id":"4JP87F-Gwgw-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tried to switch loss function after 7 epochs, did not work"],"metadata":{"id":"IT62ftzP2uv1"}},{"cell_type":"code","source":["    def forward(self, batch):\n","        # Getting Image and Text Features\n","        image_features = self.image_encoder(batch[\"image\"])\n","        text_features = self.text_encoder(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n","        batch_size = batch['input_ids'].shape[0]\n","\n","        # Getting Image and Text Embeddings (with same dimension)\n","        image_embeddings = self.image_projection(image_features)\n","        text_embeddings = self.text_projection(text_features)\n","        criterion = nn.CrossEntropyLoss(reduction = \"sum\").to(CFG.device)\n","\n","        # Cross-modal contrastive alignment (CLIP)\n","        logits_text_per_image = image_embeddings @ text_embeddings.T / self.temperature\n","        logits_image_per_text = logits_text_per_image.T\n","        target = torch.arange(batch_size).long().to(CFG.device, non_blocking = True)\n","        contrastive_loss = (criterion(logits_text_per_image, target) + criterion(logits_image_per_text, target)) / 2\n","\n","        # In-modal consistency (CyCLIP)\n","        logits_image_per_image = image_embeddings @ image_embeddings.T / self.temperature\n","        logits_text_per_text = text_embeddings @ text_embeddings.T / self.temperature\n","        inmodal_cyclic_loss = (logits_image_per_image - logits_text_per_text).square().mean() * (self.temperature * self.temperature) * batch_size\n","\n","        # Cross-modal consistency (CyCLIP)\n","        crossmodal_cyclic_loss = (logits_text_per_image - logits_image_per_text).square().mean() * (self.temperature * self.temperature) * batch_size\n","\n","        cyclic_loss = CFG.cylambda1 * inmodal_cyclic_loss + CFG.cylambda2 * crossmodal_cyclic_loss\n","\n","        loss = contrastive_loss + cyclic_loss if CFG.global_epoch > 7 else contrastive_loss\n","\n","        correct_preds = num_of_correct_preds(logits_image_per_text, batch['caption'])\n","\n","        return loss, correct_preds"],"metadata":{"id":"tNmFaBSs2tTF"},"execution_count":null,"outputs":[]}]}